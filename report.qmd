---
title: "Polvices polvando polvivamente"
format:
   pdf:
       include-in-header:
           - text: |
                \usepackage{todonotes}
                \usepackage{graphicx}
                \usepackage{amsmath}
       documentclass: asaproc
       classoption: [11pt]
editor: source
cite-method: biblatex
bibliography: Polvices.bib
biblatexoptions: 
  - citestyle=authoryear
author:
  - name: "Alberto Rocha \\thanks{Instituto Português do Mar e da Atmosfera}"
    corresponding: true
  - name: "Ana Moreno \\thanks{Instituto Português do Mar e da Atmosfera}"
    corresponding: false
number-sections: true
editor_options: 
  chunk_output_type: console
---

```{r}
#| eval: false
#| echo: false
tinytex::parse_install("report.log")
tinytex::tlmgr_update()


# https://cameronpatrick.com/post/2023/07/quarto-thesis-formatting/
```

```{r setup}
#| include: false

library(CatDyn)
library(RTMB)
library(wesanderson)
library(tidyverse)
library(xtable)
library(tmbstan)
library(shinystan)

source('scripts/custom_catdyn_fit.R')
source('scripts/custom_catdyn_bsd.R')
source('scripts/funcoes_catdyn.R')

load("data/df_effort_m_mbw_otb.Rdata")
load('data/mbw_model.Rdata')

mod_aux = lm(df_effort$catch ~ df_effort$effort)

# Fix a couple of outliers
df_effort = 
  df_effort %>% 
  mutate(catch = case_when(year_sale == 2005 &
                             month_sale == '09' ~
                             effort * mod_aux$coefficients[2] +
                             mod_aux$coefficients[1],
                           T ~ catch),
         catch_otb = case_when(year_sale == 2005 &
                                 month_sale == '09' ~
                                 effort_otb * mod_aux$coefficients[2] +
                                 mod_aux$coefficients[1],
                               T ~ catch_otb)) %>% 
  mutate(catch_otb = case_when(catch_otb == 0 ~ mean(catch_otb), 
                               T ~ catch_otb),
         effort_otb = case_when(effort_otb  < 150 ~ mean(effort_otb),
                                T ~ effort_otb))

```

```{r estim_catdyn}
cat_df = as.CatDynData(x=df_effort %>% 
                         filter(as.numeric(
                           as.character(year_sale)) %in% c(2006:2023)),
                       step="month",
                       fleet.name="MIS-S",
                       coleff=4,
                       colcat=3,
                       colmbw=9,
                       unitseff="trips",
                       unitscat="kg",
                       unitsmbw="kg",
                       nmult="thou",
                       season.dates=c(as.Date("2006-01-01"),
                                      # as.Date("1995-12-24")))
                                      last_date_of_week(2023, 52)-1))

# plot.CatDynData(cat_df,
#                 mark = T,
#                 offset = c(0,1,10),
#                 hem = 'N')

indice_manual = 
  list(
    10,11,12,
    12,12,10,11,12,
    11,10,12,7,10,
    12,11,12,12,10)

for(i in 0:(length(indice_manual)-1)){
  indice_manual[[i+1]] = 12*i + indice_manual[[i+1]]
}

# unlist(indice_manual)
# 
# cat_df$Data$`MIS-S` %>% 
#   mutate(year = ((time.step -1) %/% 12),
#          x2 = rep(1:12,length(year)/12)) %>% 
#   ggplot() + 
#   geom_line(aes(color = factor(year)),
#             linewidth = 1) + 
#   aes(y = spikecat,
#       x = x2) + 
#   facet_wrap(year ~.) + 
#   scale_color_manual(values = colorRampPalette(wes_palette('Zissou1'))(
#     length(cat_df$Data$`MIS-S`$time.step)/12)) + 
#   theme_bw() + 
#   theme(legend.position = 'none')
# 
# 
# #first trial
# a = Sys.time()
# fit_null =
#   trialer(cat_df,
#            p = 18,
#                 M = 0.05976,
#                 N0.ini = 14020, 
#                 P = indice_manual,
#                 P.ini  = list(
#                 5744,40315,3534,
#                 21558,2766,9735,
#                 55453,3438,16525,
#                 10746,14552,2524,
#                 22789,12567,34463,
#                 20000,20000,20000),
#                 k.ini = 0.00003546,
#                 alpha.ini = 1.1455,
#                 beta.ini  = 0.6134,
#                 distr = i,
#                 method = j,
#                 itnmax = 10000,
#                 disp = list(100))
# b = Sys.time()
# b-a
# # 
# # # all fits
# a = Sys.time()
# distribuicoes = c("gamma", "lognormal","normal","negbin","aplnormal", "apnormal")
# optimizadores = c('CG', 'spg', 'BFGS', 'Nelder-Mead')
# gdm_log_06 = data_frame(distr = character(),
#                         methods = character())
# modelos_gdm_06 = list()
# for(i in distribuicoes){
#   for(j in optimizadores){
#     tryCatch({
#       modelos_gdm_06[[length(modelos_gdm_06)+1]] =
#         trialer(cat_df,
#                 p = 18,
#                 M = 0.05976,
#                 N0.ini = 14020, 
#                 P = indice_manual,
#                 P.ini  = list(
#                 5744,40315,3534,
#                 21558,2766,9735,
#                 55453,3438,16525,
#                 10746,14552,2524,
#                 22789,12567,34463,
#                 20000,20000,20000),
#                 k.ini = 0.00003546,
#                 alpha.ini = 1.1455,
#                 beta.ini  = 0.6134,
#                 distr = i,
#                 method = j,
#                 itnmax = 10000,
#                 disp = list(100))
# 
#       gdm_log_06[nrow(gdm_log_06)+1,1] = i
#       gdm_log_06[nrow(gdm_log_06),2] = j
#     },
#     error=function(e){print(paste(i,j))
#     })
#   }
# }
# b = Sys.time()
# b-a
# 
# resultados_06 = lapply(modelos_gdm_06, function(x){x$fit})
# 
# 
# pred_06 = lapply(modelos_gdm_06, function(x){x$pred})
# CatDynSum(x=resultados_06,
#           season=2006,
#           method=gdm_log_06$methods) %>% View


# plotador(cat_df, fit_null, pre = F,
#          post1 = T,
#          post2 = T)
# save(fit_null,
#      resultados_06,
#      pred_06,
#      gdm_log_06,
#      file = 'data/preliminar_catdyn_fits.Rdata')

load('data/preliminar_catdyn_fits.Rdata')
# plotador(cat_df, fit_null, pre = F,
#          post1 = T,
#          post2 = T)


# exclude failures
tabela = 
CatDynSum(x=resultados_06,
          season=2006,
          method=gdm_log_06$methods) %>% 
  mutate(across(everything(),
                function(x){
    as.vector(unlist(x))}))

modelos_completos = 
tabela %>% 
  mutate(indice = 1:nrow(tabela)) %>% 
  filter(!if_any(everything(), is.nan)) %>% select(indice)

# 12
tabela[12,]

res_06 = list()
res_06$pred = pred_06[[modelos_completos$indice]]
res_06$fit = resultados_06[[modelos_completos$indice]]

annual_biomass =
  CatDynBSD(res_06$fit,
            method = names(res_06$fit$Model),
            multi = T,
            mbw.sd = predicos$se.fit) %>% 
  mutate(TimeStep = 216,
         x =seq(2006,2023+11/12,1/12)) 

```

```{r}
ggplot() + 
  geom_line(aes(x = annual_biomass$x,
                y = annual_biomass$B.ton,
                group = 1),
            size = 1) +
  geom_ribbon(aes(x = annual_biomass$x,
                  y = annual_biomass$B.ton,
                  ymin= annual_biomass$B.ton- 2*annual_biomass$B.ton.SE,
                  ymax= annual_biomass$B.ton+ 2*annual_biomass$B.ton.SE),
              alpha=0.2) +

  # coord_cartesian(ylim = c(0, 300000), xlim = c(1995,2024)) +
  theme_bw()

results = res_06$pred$Model$Results %>% 
  as.data.frame() %>% 
  mutate(x = 1:216)

natural_mortality = res_06$fit$Model$CG$bt.par$M
natural_mortality_sd = res_06$fit$Model$CG$bt.stdev[['M']]

# Fishing Mortality
results %>% 
  ggplot() + 
  geom_line(aes(x = Period.month,
                y = `Observed.F.1/month`),
            col = 'tomato',
            size = 1) +
  geom_line(aes(x = Period.month,
                y = `Predicted.F.1/month`),
            col = 'darkred',
            size = 1,
            linetype = 2) + 
  geom_hline(yintercept = natural_mortality,
            col = 'darkgreen',
            size = 1,
            linetype = 1) +
  geom_hline(yintercept = natural_mortality + 2*natural_mortality,
             col = 'darkgreen',
             size = 1,
             linetype = 2) +
  geom_hline(yintercept = natural_mortality - 2*natural_mortality,
             col = 'darkgreen',
             size = 1,
             linetype = 2) +
  theme_bw()

# Exploitation Rate
# Exploitation Rate

results %>% 
  ggplot() + 
  geom_line(aes(x = Period.month,
                y = `Observed.Explotrate`),
            col = 'tomato',
            size = 1) +

  geom_line(aes(x = Period.month,
                y = `Predicted.Explotrate`),
            col = 'darkred',
            size = 1,
            linetype = 2) +
  geom_line(aes(x = Period.month,
                y = `Observed.F.1/month`/(`Observed.F.1/month`+ natural_mortality)),
            col = 'purple',
            size = 1) +
  # geom_hline(yintercept = 0.4,
  #            col = 'darkgreen',
  #            size = 1,
  #            linetype = 1) +
  theme_bw()


results %>% 
  summarise(pilas = `Observed.F.1/month`/(`Observed.F.1/month`+natural_mortality),
            expo = Observed.Explotrate) %>% 
  mutate(teste = pilas/expo)
```

# RTMB

## Formulation, step by step

Consider the condensed formulation of this model, where catch in numbers is modeled as a function of observed effort and several parameters.

\begin{equation}
    \begin{aligned}
    \label{eq:catdyn_1}
C_t = kE_t^\alpha N_t^\beta = m kE_t^\alpha f_t(M,N_0, C_{i<t}, R, S) \\
\textrm{with} \quad m = e^{-\frac{M}{2}}
    \end{aligned}
\end{equation}

The author typically considers several distributions for this process and tries them, along as several optimizers, in a systematic, grid-search-like approach.

In order to incorporate this model in RTBM, we will have to break down the abundance estimate ($N_t^\beta$) into chunks that are easier to process. First we present the complete formulation and then we'll break down the chunks of $f(t)$ *ie*, everything that is raised to $\beta$.

\begin{equation}
    \begin{aligned}
    \label{eq:catdyn_2}
C_t = kE_t^\alpha  m \left( N_0 e^{-Mt} -m \left[ \sum_{i=i}^{i=t-1} C_{i,i} e^{-M(t-i-1)} \right] + \sum_{j=1}^{j=u} I_j R_j e^{-M(t-\tau_j)} - \sum_{l=1}^{l=v} J_l S_l e^{-M(t-\upsilon_l} \right) ^ \beta
    \end{aligned}
\end{equation}

## Chunk 1: Exponential Population Growth

\begin{equation}
    \begin{aligned}
    \label{eq:catdyn_ch1}
N_0 e^{-Mt}
    \end{aligned}
\end{equation}

The first term consists simply of natural population decay driven by natural mortality $M$, as illustrated below. Unlike other models, birth-driven input (recruitment) is not incorporated at this stage in the model. The model is only concerned with individuals available to the fishery, so until recruits attain a size that makes them eligible they are not accounted for. Their entry into the fishery will be modelled as discrete spikes.

```{r}
#| echo: false
#| warning: false

N0 = 1000000
x = 1:348
M = 0.05

res_1 = c()
# chunk 1
for(tt in 1:length(x)){
ch1 = N0 * exp(-M*tt)

res_1[tt] = ch1
}

  ggplot() + 
  geom_line(aes(x = x,
                y = res_1)) + 
  theme_bw() + 
  labs(title = 'chunk 1')
```

## Chunk 2: Catch carry over

\begin{equation}
    \begin{aligned}
    \label{eq:catdyn_ch2}
 -m \left[ \sum_{i=i}^{i=t-1} C_{i,i} e^{-M(t-i-1)} \right] 
    \end{aligned}
\end{equation}

This section incorporates the expected value for the catch in each year, with decay from natural mortality that intensifies the further you are from that year. It is explicitly recursive, unlike chunk 1, and therefore the code must account for that correctly. 

It is unclear if $C_i$ accounts for the *entire* estimate in previous iterations or simply previous observations. For this report, the second alternative was implemented in the objective function

## Chunk 3: Recruitment pulse input

\begin{equation}
    \begin{aligned}
    \label{eq:catdyn_2}
    \sum_{j=1}^{j=u} I_j R_j e^{-M(t-\tau_j)}
    \end{aligned}
\end{equation}

This chunk adds the recruitment pulses at timing $\tau_j$, of magnitude $R_j$, modulated by the time passed between $t$ and $\tau_j$. There is a quirk in this formulation regarding the use of an indicator vector $I_j$, which in all papers published by the author of CatDyn is said to be 0 when $\tau_j < t$ and 1 afterwards. This interpretation, combined with the double negative signals in the exponential component of the chunk, leads to a scenario where recruitment spikes that occur after the time step $t$ contribute to $C_t$, where as spikes before $t$ are nullified by the 0 in the indicator vector $I_j$. 

In this work, an alternative formulation that is sometimes used by the author where the indicator vector is ommited. This does not mitigate the exponent signal effect, however.

Finally, the timings for the perturbations in the vector $\tau_j$ must be manually inserted by the user after visual inspection of the data. The author has develloped an approach regarding catch spike statistics that will not be discussed here, so for the sake of this report $\tau_j$ will be inserted manually into the parameter list.

There is a similar chunk with an inverted signal that accounts for emigration pulses; in octopus fisheries this is thought to reflect the moments when females leave the fishery after spawning. Currently it is assumed, due to the fishing gears used in the portuguese fishery, that such an exit does not occur in this particular case.

## Parameters to be estimated

-   $\alpha$ is the abundance response

-   $\beta$ is the effort response

Both allow non-linearity for $E_t$ and $N_t$;

-   $k$ is a scaling factor

-   $M$ is the natural mortality (with $m = e^{-\frac{M}{2}}$)

-   $N_0$ is the initial abundance of the stock at $t_0$

-  $R_j$ are the recruitment pulse magnitudes

## Model 3.1: GDM, as seen on CatDyn



```{r}
#| results: hide
#| warning: false

dat = list()

dat$Ct = as.vector(df_effort$catch_otb[as.numeric(
  as.character(
    df_effort$year_sale))>2005]/
                     df_effort$res[as.numeric(
                       as.character(
                         df_effort$year_sale))>2005])  # catches

dat$Et = as.vector(df_effort$effort_otb[as.numeric(
  as.character(
    df_effort$year_sale))>2005]) # effort

indice_manual_2 = 
  list(
    10,11,12,
    12,12,10,11,12,
    11,12,10,12,11,
    12,12,12,12,10)

indice_manual_v = 
  list(
    7,7,7,
    7,7,7,7,7,
    7,7,7,7,7,
    7,7,7,7,7)

for(i in 0:(length(indice_manual_2)-1)){
  indice_manual_2[[i+1]] = 12*i + indice_manual_2[[i+1]]
}

for(i in 0:(length(indice_manual_v)-1)){
  indice_manual_v[[i+1]] = 12*i + indice_manual_v[[i+1]]
}
dat$u = unlist(indice_manual_2) # recruitment pulse timings
dat$v = unlist(indice_manual_v)

# initialize parameter list with initial estimates
par = list()

# par$Rt_scaled = as.vector(rep(20,
#                               length(dat$u)))# init empty vector

par$Rt_scaled = c(57.744,40.315,3.534,21.558,2.766,
                     9.735,55.453,3.438,16.525,10.746,
                     14.552,2.524,22.789,12.567,34.463,
                     15.000,15.000,15.000)

par$Ft_scaled = as.vector(rep(2,
                              length(dat$u)))# init empty vector

par$logalpha = log(.5)
par$logbeta = log(.5)
par$logK = log(0.001)
par$logN0_scaled = log(6000000) # inserir nmult
par$logM = log(0.001)

par$logsdCt = 20

# initialize joint negative loglikelihood function
jnll = function(par){
  getAll(par, dat) # invoke all the parameters and data
  
  # gather and cleanup pars
  Ct = OBS(Ct)
  alpha = exp(logalpha)
  beta = exp(logbeta)
  K = exp(logK)
  N0 = 1e6 * exp(logN0_scaled)
  # N0 = exp(logN0)
  M = exp(logM)
  sdCt = exp(logsdCt)
  Rt = 1e6 * Rt_scaled
  Ft = 1e6 * Ft_scaled
  
  # assemble model    
  jnll = 0 # init jnll
 
  # Initial values
 
  catch = advector(rep(0, length(dat$Ct)))
  
    for(mes in 1:length(dat$Ct)){
       # core
    m = exp(-M/2)
    
    if(mes == 1){
      pred = K*Et[mes]^alpha * m * (N0*exp(-M*1))^beta
    }else{
    
    core = K*(Et[mes]^alpha) * m 
    
    # M-driven decay
    
    part1 = N0*exp(-M*mes)
    
    # catch aggregation
    
    ## Using the observation series 
    # part2 = 0
    # for(mes_ant in seq_len(length(dat$Ct)-1)){
    #   part2 = part2 + Ct[mes_ant]*exp(-M*(mes-mes_ant-1))}
    
    ## Using the expected catch recursively
    part2 = 0
      # if(mes != 1){
    for(mes_ant in 1:(mes-1)){
    part2 = part2 + catch[mes_ant]*exp(-M*(mes-mes_ant-1))}

    # }
    # Recruitment pulses
    
    part3 = 0
    for(j in seq_along(u[u<=mes])){
      part3 = part3 + Rt[j]*exp(-M*(mes-u[j]))}
    
    part4 = 0
    for(j in seq_along(v[v<=mes])){
      part4 = part4 + Ft[j]*exp(-M*(mes-v[j]))}
    
    
    # Assemble
    pred = core * (part1 - m * part2 + part3 - part4)^beta}
    
    catch[mes] = advector(pred)
    
    jnll = jnll - dnorm(Ct[mes], pred, sdCt, log = T)
   
  }
  REPORT(catch)
  jnll
}

# quick test: do we get a number? This number should be a likelihood.
jnll(par)

obj7 = MakeADFun(jnll, par, random = c('Rt_scaled', 'Ft_scaled'))


obj7$report()['catch']

fit7 = nlminb(obj7$par, obj7$fn, obj7$gr)

sdr7 = sdreport(obj7)
pl7 = as.list(sdr7,"Est")
plsd7 = as.list(sdr7,"Std")
```

\todo[inline]{NaN warnings were also produced here}

```{r}
#| output: asis
#| echo: false
#| warning: false
summary(sdr7) %>% 
  as.data.frame() %>% 
  slice(-c(7:36)) %>%
  xtable %>% 
  print(comment = F,
        sanitize.text.function = function(x) 
          {gsub("_", "\\\\_", x)})
```

```{r}
# Calculate AIC
logLik_value7 = -fit7$objective
k = length(fit7$par)
aic_value7 = 2 * k - 2 * logLik_value7

# Calculate WAIC
log_lik7 = numeric(length(dat$Ct))

# Vector of predicted means
meanvec7 = numeric(1)
  m = exp(-exp(pl7$logM)/2)
  
  # catch[1] = K*Et[1]^alpha * m *(N0*exp(-M*1))^beta
  meanvec7[1] = exp(pl7$logK)*
    (dat$Et[1]^exp(pl7$logalpha)) *
    m *(1e9*exp(pl7$logN0_scaled)) *
    exp((-exp(pl7$logM)*1))^exp(pl7$logbeta)
  
  for(mes in 2:length(dat$Ct)){
       # core
    
    core = exp(pl7$logK)*(dat$Et[mes]^exp(pl7$logalpha)) * m 
    
    # M-driven decay
    
    part1 = (1e9 * exp(pl7$logN0_scaled)) * exp(-exp(pl7$logM)*mes)
    
    # catch aggregation
    
    ## Using the observation series 
    # part2 = 0
    # for(mes_ant in seq_len(length(dat$Ct)-1)){
    #   part2 = part2 + Ct[mes_ant]*exp(-M*(mes-mes_ant-1))}
    
    ## Using the expected catch recursively
    part2 = 0
      # if(mes != 1){
    for(mes_ant in seq_len(length(meanvec7))){
    part2 = part2 + meanvec7[mes_ant]*
      exp(-exp(pl7$logM)*(mes-mes_ant-1))
    }
    # }
    # Recruitment pulses
    
    part3 = 0
    for(j in seq_along(dat$u[dat$u<=mes])){
      part3 = part3 + pl7$Rt[j]*exp(-exp(pl7$logM)*(mes-dat$u[j]))}
    
    
    # Assemble
    base = part1 - m * part2 + part3
    pred = core * (base)^exp(pl7$logbeta)
    meanvec7[mes] = pred}
  # for(mes in seq_along(dat$Ct)){
  #   
  #   m = exp(-exp(pl7$logM)/2)
  #   
  #   # core
  #   
  #   core = exp(pl7$logK)*(dat$Et[mes]^exp(pl7$logalpha)) * m 
  #   
  #   # M-driven decay
  #   
  #   part1 = exp(pl7$logN0)*exp(-exp(pl7$logM)*mes)
  #   
  #   # catch aggregation
  #    
  #   part2 = 0
  #   for(mes_ant in seq_len(length(dat$Ct)-1)){
  #     part2 = part2 + dat$Ct[mes_ant]*exp(-exp(pl7$logM)*(mes-mes_ant-1))}
  #   
  #   # Recruitment pulses
  #   
  #   part3 = 0
  #   for(j in seq_along(dat$u[dat$u<=mes])){
  #     part3 = part3 + 
  #       summary(sdr7, 'random')[,'Estimate'][j]*
  #       exp(-exp(pl7$logM)*(mes-dat$u[j]))}
  #   
  #   
  #   # Assemble
  #   pred = core * (part1 -m*part2 + part3)^exp(pl7$logbeta)
  #   meanvec7[mes] = pred}
  
# Revert transformation of sigma(y)  
sdy = exp(pl7$logsdCt)

for(i in 1:length(dat$Ct)){
  log_lik7[i] = dnorm(dat$Ct[i], meanvec7[i], sdy, log=TRUE)
}

lppd7 = sum(log(mean(exp(log_lik7))))
p_waic7 = sum(var(log_lik7))
waic7 = -2 * (lppd7 - p_waic7)

```

```{r}
#| output: asis
#| echo: false

xtable(data.frame(Model = c('GMD'),
                  AIC = c(aic_value7), 
                  WAIC = c( waic7))) %>% 
  print(comment = F,
        sanitize.text.function = function(x)
          {gsub("_", "\\\\_", x)})
```

Convergence was problematic, but we did achieve plausible estimates. $M$ and $N0$ did not yield standard error estimates, and we have some negative values for $R_j$, which should not be possible. We have explicitly excluded the scenario of exit pulses, but if we attempt to bound $R_j$ to positive values the model convergence completely falls apart. Perhaps that premise should be reevaluated?

```{r}
# plot referencia catdyn
# 
results %>% 
  ggplot() + 
  geom_line(aes(x =Period.month, 
                y = Observed.Catch.kg),
            col = 'black') + 
    geom_line(aes(x =Period.month, 
                y = Predicted.Catch.kg),
            col = 'red', linetype =2) + 
  geom_line(aes(x =Period.month, 
                y = dat$Ct),
            col = 'green', linetype =2) + 
  theme_bw()
```


```{r}
#| echo: false

set.seed(1)
pred7 = rnorm(216,
              meanvec7,
              sdy)

ggplot() + 
  geom_point(aes(x = 1:216,
                y = dat$Ct)) +
   geom_line(aes(x = 1:216,
                y = pred7),
            color = 'green') + 
  geom_line(aes(x = 1:216,
                y = obj7$report()['catch'] %>% unlist()),
            color = 'red') +
  theme_bw()
```

\begin{abstract}

Polvo e o caralho (\cite{alemany_bayesian_2017})


\begin{keywords}
Bayesian, parametric, $p$-value, ICES
\end{keywords}
\end{abstract}



\section{Primary Subhead\label{intro}}

This is sample text and needs to be completely replaced before submitting your paper.

\subsection{References}

References within your paper should use the Harvard referencing format. This is sample text and needs to be completely replaced before submitting your paper. 

\subsection{Secondary Subhead}


This is sample text and needs to be completely replaced before submitting your paper.   

\section{Another Primary Subhead}

\subsection{Secondary Subhead}

This is sample text and needs to be completely replaced before submitting your paper. 

\subsubsection{Tertiary Subhead}

This is sample text and needs to be completely replaced before submitting your paper. 

\begin{table}
\caption{Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus }
\begin{center}
\begin{tabular}{ccccc}
\hline
\hline
\\[-5pt]
\multicolumn{2}{c}{Genotype} & &
\multicolumn{1}{c}{Dummy for additivity} &
\multicolumn{1}{c}{Dummy for dominance }\\
\multicolumn{1}{c}{Label} &    
\multicolumn{1}{c}{Index i} &
\multicolumn{1}{c}{Genotypic value ($\eta$)}&
\multicolumn{1}{c}{effect $\alpha$ (x)} &
\multicolumn{1}{c}{effect $\delta$ (z)}\\
\hline
qq      &1&     $\mu + \mbox{2}\alpha$  & 2&    0\\
Qq&     2&      $\mu + \alpha + \delta$&        1       &1\\
QQ&     3&      $\mu$&  0&      0\\
\hline
\end{tabular}
\end{center}
\end{table}

This is sample text and needs to be completely replaced before submitting your paper. 

\begin{figure}[t]
\centering\includegraphics[scale=.75]{fig1.eps}
\caption{Place figure caption here.}
\end{figure}

This is sample text and needs to be completely replaced before submitting your paper. 