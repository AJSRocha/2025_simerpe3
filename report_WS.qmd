---
title: "Polvices polvando polvivamente"
format:
   pdf:
       include-in-header:
           - text: |
                \usepackage{todonotes}
                \usepackage{graphicx}
                \usepackage{amsmath}
       documentclass: asaproc
       classoption: [11pt]
editor: source
cite-method: biblatex
bibliography: Polvices.bib
biblatexoptions: 
  - citestyle=authoryear
author:
  - name: "Alberto Rocha \\thanks{Instituto Português do Mar e da Atmosfera}"
    corresponding: true
  - name: "Ana Moreno \\thanks{Instituto Português do Mar e da Atmosfera}"
    corresponding: false
number-sections: true
editor_options: 
  chunk_output_type: console
---

```{r}
#| eval: false
#| echo: false
tinytex::parse_install("report.log")
tinytex::tlmgr_update()


# https://cameronpatrick.com/post/2023/07/quarto-thesis-formatting/
```

```{r setup}
#| include: false

library(CatDyn)
library(RTMB)
library(wesanderson)
library(tidyverse)
library(xtable)
library(tmbstan)
library(shinystan)

source('scripts/custom_catdyn_fit.R')
source('scripts/custom_catdyn_bsd.R')
source('scripts/funcoes_catdyn.R')

load("data/df_effort_m_mbw_otb.Rdata")
load('data/mbw_model.Rdata')

source("WS/CatDynBSD9P.R")

mod_aux = lm(df_effort$catch ~ df_effort$effort)

# Fix a couple of outliers
df_effort = 
  df_effort %>% 
  mutate(catch = case_when(year_sale == 2005 &
                             month_sale == '09' ~
                             effort * mod_aux$coefficients[2] +
                             mod_aux$coefficients[1],
                           T ~ catch),
         catch_otb = case_when(year_sale == 2005 &
                                 month_sale == '09' ~
                                 effort_otb * mod_aux$coefficients[2] +
                                 mod_aux$coefficients[1],
                               T ~ catch_otb)) %>% 
  mutate(catch_otb = case_when(catch_otb == 0 ~ mean(catch_otb), 
                               T ~ catch_otb),
         effort_otb = case_when(effort_otb  < 150 ~ mean(effort_otb),
                                T ~ effort_otb))

```

```{r estim_catdyn}

tibec.14.22.pg.1 <- read.csv("WS/tibec.14.22.pg.1.csv",header=TRUE)

tibec.14.22.pg.2 <- as.CatDynData(x=tibec.14.22.pg.1,
                                  step="month",
                                  fleet.name=c("Pelagic"),
                                  coleff=4,
                                  colcat=3,
                                  colmbw=5,
                                  unitseff="ntrips",
                                  unitscat="kg",
                                  unitsmbw="kg",
                                  nmult="thou",
                                  season.dates=c("2014-01-01","2022-12-31"))

P1.Pelagic  <- 12  #2014
P2.Pelagic  <- 24  #2015
P3.Pelagic  <- 36  #2016
P4.Pelagic  <- 47  #2017 
P5.Pelagic  <- 60  #2018 
P6.Pelagic  <- 72  #2019
P7.Pelagic  <- 84  #2020 
P8.Pelagic  <- 96  #2021
P9.Pelagic  <- 107 #2022
#
tibec.14.22.pg.dates.1  <- c(head(tibec.14.22.pg.2$Data[[1]]$time.step,1),
                             P1.Pelagic,
                             P2.Pelagic,
                             P3.Pelagic,
                             P4.Pelagic,
                             P5.Pelagic,
                             P6.Pelagic,
                             P7.Pelagic,
                             P8.Pelagic,
                             P9.Pelagic,
                             tail(tibec.14.22.pg.2$Data[[1]]$time.step,1))

M.ini             <- 0.015
N0.ini            <- 500
P1.ini.Pelagic    <- 100 #12  2014
P2.ini.Pelagic    <- 50  #24  2015
P3.ini.Pelagic    <- 50  #36  2016
P4.ini.Pelagic    <- 50  #47  2017
P5.ini.Pelagic    <- 100 #60  2018
P6.ini.Pelagic    <- 60  #72  2019
P7.ini.Pelagic    <- 350 #84  2020
P8.ini.Pelagic    <- 150 #96  2021
P9.ini.Pelagic    <- 150 #107 2022
k.ini.Pelagic     <- 2e-6
alpha.ini.Pelagic <- 1
beta.ini.Pelagic  <- 1
#
psi.ini.Pelagic    <- 0.25*sd(tibec.14.22.pg.2$Data$Pelagic$obscat.thou[tibec.14.22.pg.2$Data$Pelagic$obscat.thou>0])^2
psilog.ini.Pelagic <- 0.25*sd(log(tibec.14.22.pg.2$Data$Pelagic$obscat.thou[tibec.14.22.pg.2$Data$Pelagic$obscat.thou>0]))^2

tibec.14.22.pg.pars.ini <- log(c(M.ini,
                                 N0.ini,
                                 P1.ini.Pelagic,
                                 P2.ini.Pelagic,
                                 P3.ini.Pelagic,
                                 P4.ini.Pelagic,
                                 P5.ini.Pelagic,
                                 P6.ini.Pelagic,
                                 P7.ini.Pelagic,
                                 P8.ini.Pelagic,
                                 P9.ini.Pelagic,
                                 k.ini.Pelagic,
                                 alpha.ini.Pelagic,
                                 beta.ini.Pelagic,
                                 psi.ini.Pelagic,
                                 psilog.ini.Pelagic))
#



tibec.14.22.pg.ini.apn <- catdynexp(x=tibec.14.22.pg.2,                                 
                                    p=9,
                                    par=tibec.14.22.pg.pars.ini[1:15],
                                    dates=tibec.14.22.pg.dates.1,
                                    distr="normal")

plot(x=tibec.14.22.pg.ini.apn,
     leg.pos="topleft",
     Biom.tstep=1,
     Biom.xpos=0.25,
     Biom.ypos=0.75,
     Cat.tstep=12,
     Cat.xpos=0.25,
     Cat.ypos=0.65)
#
tibec.14.22.pg.apn.1.fit <- CatDynFit(x=tibec.14.22.pg.2,
                                      p=9,
                                      par=tibec.14.22.pg.pars.ini[1:15],
                                      dates=tibec.14.22.pg.dates.1,
                                      distr="normal",
                                      method=c("CG"),
                                      itnmax=50000)
#
tibec.14.22.pg.apn.1.fit.pred.CG <- CatDynPred(x=tibec.14.22.pg.apn.1.fit,method="CG")

x                        <- data.frame(key=rep(1:12,9),
                                       x=tibec.14.22.pg.2$Data$Pelagic$obsmbw.kg)
y                        <- aggregate(x$x,list(x$key),sd)
tibec.14.22.pg.apn.1.bsd <- CatDynBSD9P(x=tibec.14.22.pg.apn.1.fit,
                                        method="CG",
                                        multi=TRUE,
                                        mbw.sd=y$x)

annual_biomass =
tibec.14.22.pg.apn.1.bsd %>% 
  mutate(TimeStep = 108,
         x =seq(2014,2022+11/12,1/12))

```

```{r}
ggplot() + 
  geom_line(aes(x = annual_biomass$x,
                y = annual_biomass$B.ton,
                group = 1),
            size = 1) +
  geom_ribbon(aes(x = annual_biomass$x,
                  y = annual_biomass$B.ton,
                  ymin= annual_biomass$B.ton- 2*annual_biomass$B.ton.SE,
                  ymax= annual_biomass$B.ton+ 2*annual_biomass$B.ton.SE),
              alpha=0.2) +

  # coord_cartesian(ylim = c(0, 300000), xlim = c(1995,2024)) +
  theme_bw()

results = tibec.14.22.pg.apn.1.fit.pred.CG$Model$Results %>% 
  as.data.frame() %>% 
  mutate(x = 1:108)

natural_mortality = tibec.14.22.pg.apn.1.fit $Model$CG$bt.par$M
natural_mortality_sd = tibec.14.22.pg.apn.1.fit $Model$CG$bt.stdev[['M']]

# Fishing Mortality
results %>% 
  ggplot() + 
  geom_line(aes(x = Period.month,
                y = `Observed.F.1/month`),
            col = 'tomato',
            size = 1) +
  geom_line(aes(x = Period.month,
                y = `Predicted.F.1/month`),
            col = 'darkred',
            size = 1,
            linetype = 2) + 
  geom_hline(yintercept = natural_mortality,
            col = 'darkgreen',
            size = 1,
            linetype = 1) +
  geom_hline(yintercept = natural_mortality + 2*natural_mortality,
             col = 'darkgreen',
             size = 1,
             linetype = 2) +
  geom_hline(yintercept = natural_mortality - 2*natural_mortality,
             col = 'darkgreen',
             size = 1,
             linetype = 2) +
  theme_bw()

# Exploitation Rate
# Exploitation Rate

results %>% 
  ggplot() + 
  geom_line(aes(x = Period.month,
                y = `Observed.Explotrate`),
            col = 'tomato',
            size = 1) +

  geom_line(aes(x = Period.month,
                y = `Predicted.Explotrate`),
            col = 'darkred',
            size = 1,
            linetype = 2) + 
  geom_hline(yintercept = 0.4) + 
  # geom_line(aes(x = Period.month,
  #               y = `Observed.F.1/month`/(`Observed.F.1/month`+ natural_mortality)),
  #           col = 'purple',
  #           size = 1) +
  # geom_hline(yintercept = 0.4,
  #            col = 'darkgreen',
  #            size = 1,
  #            linetype = 1) +
  theme_bw()


results %>% 
  summarise(pilas = `Observed.F.1/month`/(`Observed.F.1/month`+natural_mortality),
            expo = Observed.Explotrate) %>% 
  mutate(teste = pilas/expo)
```

# RTMB

```{r}
#| results: hide
#| warning: false

dat = list()

dat$Ct = as.vector(tibec.14.22.pg.2$Data$Pelagic$obscat.thou)  # catches

dat$Et = as.vector(tibec.14.22.pg.2$Data$Pelagic$obseff.ntrips) # effort

indice_manual = c(12,24,36,47,60,72,84,96,107)

I = list()
for(i in 1:length(indice_manual)){
  I[[i]] = rep(1,length(dat$Ct))
  # I[[i]][1:length(I[[i]])<indice_manual[i]] = 0
  I[[i]][1:indice_manual[i]-1] <- 0
}

dat$u = unlist(indice_manual)

# initialize parameter list with initial estimates
par = list()

# par$Rt_scaled = as.vector(rep(20,
#                               length(dat$u)))# init empty vector

par$Rt_scaled = c(P1.ini.Pelagic, P2.ini.Pelagic, P3.ini.Pelagic,
                  P4.ini.Pelagic, P5.ini.Pelagic, P6.ini.Pelagic,
                  P7.ini.Pelagic, P8.ini.Pelagic, P9.ini.Pelagic)

# par$Ft_scaled = as.vector(rep(2,
                              # length(dat$u)))# init empty vector

par$logalpha = log(alpha.ini.Pelagic)
par$logbeta = log(beta.ini.Pelagic)
par$logK = log(k.ini.Pelagic)
par$logN0_scaled = log(N0.ini) # inserir nmult
par$logM = log(M.ini)

par$logsdCt = 20

# initialize joint negative loglikelihood function
jnll = function(par){
  getAll(par, dat) # invoke all the parameters and data
  
  # gather and cleanup pars
  Ct = OBS(Ct)
  alpha = exp(logalpha)
  beta = exp(logbeta)
  K = exp(logK)
  N0 = 1 * exp(logN0_scaled)
  # N0 = exp(logN0)
  M = exp(logM)
  sdCt = exp(logsdCt)
  Rt = 1 * Rt_scaled

  
  # assemble model    
  jnll = 0 # init jnll
 
  # Initial values
 
  catch = advector(rep(0, length(dat$Ct)))
  
    for(mes in 1:length(dat$Ct)){
    # core
    m = exp(-M/2)
    
    if(mes == 1){
      pred = K*Et[mes]^alpha * m * (N0*exp(-M*1))^beta
    }else{
    
    core = K*(Et[mes]^alpha) * m 
    
    # M-driven decay
    
    part1 = N0*exp(-M*mes)
    
    
    part2 = 0
    
    for(mes_ant in 1:(mes-1)){
    part2 = part2 + catch[mes_ant]*exp(-M*(mes-mes_ant-1))}

    
    # Recruitment pulses
    
    part3 = 0
    for(j in seq_along(u)){
      part3 = part3 + I[[j]][mes] * Rt[j]*exp(-M*(mes-u[j]))}
    
    part4 = 0

    # Assemble
    pred = core * (part1 - m * part2 + part3 - part4)^beta}
    
    catch[mes] = advector(pred)
    
    jnll = jnll - dnorm(Ct[mes], pred, sdCt, log = T)
   
  }
  REPORT(catch)
  jnll
}

# quick test: do we get a number? This number should be a likelihood.
jnll(par)

obj7 = MakeADFun(jnll, par, random = c('Rt_scaled'))


obj7$report()['catch']

fit7 = nlminb(obj7$par, obj7$fn, obj7$gr)

sdr7 = sdreport(obj7)
pl7 = as.list(sdr7,"Est")
plsd7 = as.list(sdr7,"Std")
```

# ALT

```{r}
#| results: hide
#| warning: false

dat = list()
dat$Ct = as.vector(tibec.14.22.pg.2$Data$Pelagic$obscat.thou)         # observed catch
dat$Et = as.vector(tibec.14.22.pg.2$Data$Pelagic$obseff.ntrips)       # effort
dat$u = c(12, 24, 36, 47, 60, 72, 84, 96, 107)                        # recruitment pulse months
nT = length(dat$Ct)
nR = length(dat$u)


I = matrix(0, nrow = nT, ncol = nR)
for (j in 1:nR) {
  I[(dat$u[j]-1):nT, j] <- 1 # -1 foi adicionado para ficar consistente com CatDyn.
}

dat$I = I

# Initial parameter values
par = list(
  Rt_scaled     = c(P1.ini.Pelagic, P2.ini.Pelagic, P3.ini.Pelagic, P4.ini.Pelagic,
                    P5.ini.Pelagic, P6.ini.Pelagic, P7.ini.Pelagic, P8.ini.Pelagic, P9.ini.Pelagic),
  logalpha      = log(alpha.ini.Pelagic),
  logbeta       = log(beta.ini.Pelagic),
  logK          = log(k.ini.Pelagic),
  logN0  = log(N0.ini),
  logM          = log(M.ini),
  logsdCt       = log(0.25 * sd(dat$Ct[dat$Ct > 0]))  # consistent with CatDyn
)


Rt_min = 0      # recruitment can't be negative
Rt_max = 1e5    # or some upper limit from prior data or biomass capacit

# initialize joint negative loglikelihood function

jnll = function(par) {
  getAll(par, dat)

  # Extract parameters
  Ct     = OBS(Ct)
  Et     = OBS(Et)
  I_mat  = OBS(I)
  alpha  = exp(logalpha)
  beta   = exp(logbeta)
  K      = exp(logK)
  N0     = exp(logN0)
  M      = exp(logM)
  sdCt   = exp(logsdCt)
  Rt     = Rt_scaled

  jnll = 0
  # Initialize predicted catch and biomass


  #comprimento = length(Ct)
nstep <- vector("numeric", nT) * alpha#init vector
mccum = vector("numeric", nT) * alpha
effeff1 = vector("numeric", nT) * alpha
effn1 = vector("numeric", nT) * alpha
predcat2 = vector("numeric", nT) * alpha

N0 = exp(logN0)
M = exp(logM)
k = exp(logK)
beta = exp(logbeta)
alpha = exp(logalpha)

  mccum[1] = 0
  nstep[1] <- N0 * exp(-M)
  for(i in 2:nT){
    mccum[i] = Ct[i-1] + mccum[i-1] * exp(-M)
    nstep[i] = N0 * exp(-M*i) + 
      sum(I[i,] * Rt * exp(-M*(i-(dat$u-1)+1))) -
      mccum[i] * exp(-M/2)
    effeff1 <- Et^(alpha)
    effn1 <- nstep^(beta)
    predcat <- k * (effeff1 * effn1) * exp(-M/2)
  }
  
  # Negative log-likelihood
  jnll = -sum(dnorm(Ct, mean = predcat, sd = sdCt, log = TRUE))
  # if (is.null(Rt)) stop("Rt is NULL — check if Rt_scaled was passed correctly.")
    REPORT(predcat)
  jnll

}



# quick test: do we get a number? This number should be a likelihood.
jnll(par)

obj7 = MakeADFun(jnll, par)

# Set bounds
lower <- list(
  Rt_scaled = rep(Rt_min, 9),
  logalpha = -10, logbeta = -10, logK = -10,
  logN0_scaled = -10, logM = -10, logsdCt = -10
)

upper <- list(
  Rt_scaled = rep(Rt_max, 9),
  logalpha = 10, logbeta = 10, logK = 10,
  logN0_scaled = 10, logM = 10, logsdCt = 10
)

# Run optimizer
fit7 = nlminb(obj7$par, obj7$fn, obj7$gr,
  lower = unlist(lower),
  upper = unlist(upper))

# Retrieve predicted catch
predicted_catch = obj7$report()$predcat

```

```{r}
# tibec.14.22.pg.apn.1.fit.pred.CG$Model$Results['Predicted.Catch.thou']
# catch


ggplot() + 
  geom_line(aes(x = 1:108,
                y = unlist(tibec.14.22.pg.apn.1.fit.pred.CG$Model$Results['Predicted.Catch.thou']))) + 
  geom_line(aes(x = 1:108,
                y = predicted_catch), col = 'red') + 
  theme_bw()


ggplot() + 
  geom_line(aes(x = 1:9,
                y = unlist(tibec.14.22.pg.apn.1.fit$Model$CG$bt.par[3:11])))+ 
  geom_line(aes(x = 1:9,
                y =  fit7$par[1:9]), col = 'red') + 
    geom_line(aes(x = 1:9,
                y =  par$Rt_scaled), col = 'green') + 
  theme_bw()

```


















\todo[inline]{NaN warnings were also produced here}

```{r}
#| output: asis
#| echo: false
#| warning: false
summary(sdr7) %>% 
  as.data.frame() %>% 
  slice(-c(7:36)) %>%
  xtable %>% 
  print(comment = F,
        sanitize.text.function = function(x) 
          {gsub("_", "\\\\_", x)})
```

```{r}
# Calculate AIC
logLik_value7 = -fit7$objective
k = length(fit7$par)
aic_value7 = 2 * k - 2 * logLik_value7

# Calculate WAIC
log_lik7 = numeric(length(dat$Ct))

# Vector of predicted means
meanvec7 = numeric(1)
  m = exp(-exp(pl7$logM)/2)
  
  # catch[1] = K*Et[1]^alpha * m *(N0*exp(-M*1))^beta
  meanvec7[1] = exp(pl7$logK)*
    (dat$Et[1]^exp(pl7$logalpha)) *
    m *(1e9*exp(pl7$logN0_scaled)) *
    exp((-exp(pl7$logM)*1))^exp(pl7$logbeta)
  
  for(mes in 2:length(dat$Ct)){
       # core
    
    core = exp(pl7$logK)*(dat$Et[mes]^exp(pl7$logalpha)) * m 
    
    # M-driven decay
    
    part1 = (1e9 * exp(pl7$logN0_scaled)) * exp(-exp(pl7$logM)*mes)
    
    # catch aggregation
    
    ## Using the observation series 
    # part2 = 0
    # for(mes_ant in seq_len(length(dat$Ct)-1)){
    #   part2 = part2 + Ct[mes_ant]*exp(-M*(mes-mes_ant-1))}
    
    ## Using the expected catch recursively
    part2 = 0
      # if(mes != 1){
    for(mes_ant in seq_len(length(meanvec7))){
    part2 = part2 + meanvec7[mes_ant]*
      exp(-exp(pl7$logM)*(mes-mes_ant-1))
    }
    # }
    # Recruitment pulses
    
    part3 = 0
    for(j in seq_along(dat$u[dat$u<=mes])){
      part3 = part3 + pl7$Rt[j]*exp(-exp(pl7$logM)*(mes-dat$u[j]))}
    
    
    # Assemble
    base = part1 - m * part2 + part3
    pred = core * (base)^exp(pl7$logbeta)
    meanvec7[mes] = pred}
  # for(mes in seq_along(dat$Ct)){
  #   
  #   m = exp(-exp(pl7$logM)/2)
  #   
  #   # core
  #   
  #   core = exp(pl7$logK)*(dat$Et[mes]^exp(pl7$logalpha)) * m 
  #   
  #   # M-driven decay
  #   
  #   part1 = exp(pl7$logN0)*exp(-exp(pl7$logM)*mes)
  #   
  #   # catch aggregation
  #    
  #   part2 = 0
  #   for(mes_ant in seq_len(length(dat$Ct)-1)){
  #     part2 = part2 + dat$Ct[mes_ant]*exp(-exp(pl7$logM)*(mes-mes_ant-1))}
  #   
  #   # Recruitment pulses
  #   
  #   part3 = 0
  #   for(j in seq_along(dat$u[dat$u<=mes])){
  #     part3 = part3 + 
  #       summary(sdr7, 'random')[,'Estimate'][j]*
  #       exp(-exp(pl7$logM)*(mes-dat$u[j]))}
  #   
  #   
  #   # Assemble
  #   pred = core * (part1 -m*part2 + part3)^exp(pl7$logbeta)
  #   meanvec7[mes] = pred}
  
# Revert transformation of sigma(y)  
sdy = exp(pl7$logsdCt)

for(i in 1:length(dat$Ct)){
  log_lik7[i] = dnorm(dat$Ct[i], meanvec7[i], sdy, log=TRUE)
}

lppd7 = sum(log(mean(exp(log_lik7))))
p_waic7 = sum(var(log_lik7))
waic7 = -2 * (lppd7 - p_waic7)

```

```{r}
#| output: asis
#| echo: false

xtable(data.frame(Model = c('GMD'),
                  AIC = c(aic_value7), 
                  WAIC = c( waic7))) %>% 
  print(comment = F,
        sanitize.text.function = function(x)
          {gsub("_", "\\\\_", x)})
```

Convergence was problematic, but we did achieve plausible estimates. $M$ and $N0$ did not yield standard error estimates, and we have some negative values for $R_j$, which should not be possible. We have explicitly excluded the scenario of exit pulses, but if we attempt to bound $R_j$ to positive values the model convergence completely falls apart. Perhaps that premise should be reevaluated?

```{r}
# plot referencia catdyn
# 
results %>% 
  ggplot() + 
  geom_line(aes(x =Period.month, 
                y = Observed.Catch.kg),
            col = 'black') + 
    geom_line(aes(x =Period.month, 
                y = Predicted.Catch.kg),
            col = 'red', linetype =2) + 
  theme_bw()
```


```{r}
#| echo: false

set.seed(1)
pred7 = rnorm(108,
              meanvec7,
              sdy)

ggplot() + 
  geom_point(aes(x = 1:108,
                y = dat$Ct)) +
   geom_line(aes(x = 1:108,
                y = pred7),
            color = 'green') + 
  # geom_line(aes(x = 1:108,
  #               y = obj7$report()['catch'] %>% unlist()),
  #           color = 'red') +
  theme_bw()
```

\begin{abstract}

Polvo e o caralho (\cite{alemany_bayesian_2017})


\begin{keywords}
Bayesian, parametric, $p$-value, ICES
\end{keywords}
\end{abstract}



\section{Introduction\label{intro}}

This is sample text and needs to be completely replaced before submitting your paper.

\section{Methodology}

\subsection{CatDyn}

The fishery was assessed with *MAGD* in a previous work. In the current work, the same premises were adopted.

* Purse seine landings were discarded, for being too small
* Landings and effort from the polyvalent and bottom trawl fleets were included since no significant differences between their catch and effort relationship were observed. In this fashion, captures from near shore and coast fisheries were accounted for.
* Models were checked for gradient in parameter larger than 1


\section{References}

References within your paper should use the Harvard referencing format. This is sample text and needs to be completely replaced before submitting your paper. 

\subsection{Secondary Subhead}


This is sample text and needs to be completely replaced before submitting your paper.   

\section{Another Primary Subhead}

\subsection{Secondary Subhead}

This is sample text and needs to be completely replaced before submitting your paper. 

\subsubsection{Tertiary Subhead}

This is sample text and needs to be completely replaced before submitting your paper. 

\begin{table}
\caption{Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus Genotypes and Their Genotypic Values for a Diallelic Locus }
\begin{center}
\begin{tabular}{ccccc}
\hline
\hline
\\[-5pt]
\multicolumn{2}{c}{Genotype} & &
\multicolumn{1}{c}{Dummy for additivity} &
\multicolumn{1}{c}{Dummy for dominance }\\
\multicolumn{1}{c}{Label} &    
\multicolumn{1}{c}{Index i} &
\multicolumn{1}{c}{Genotypic value ($\eta$)}&
\multicolumn{1}{c}{effect $\alpha$ (x)} &
\multicolumn{1}{c}{effect $\delta$ (z)}\\
\hline
qq      &1&     $\mu + \mbox{2}\alpha$  & 2&    0\\
Qq&     2&      $\mu + \alpha + \delta$&        1       &1\\
QQ&     3&      $\mu$&  0&      0\\
\hline
\end{tabular}
\end{center}
\end{table}

This is sample text and needs to be completely replaced before submitting your paper. 

\begin{figure}[t]
\centering\includegraphics[scale=.75]{fig1.eps}
\caption{Place figure caption here.}
\end{figure}

This is sample text and needs to be completely replaced before submitting your paper. 